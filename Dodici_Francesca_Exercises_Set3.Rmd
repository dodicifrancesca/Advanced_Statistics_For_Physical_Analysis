---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.3
  kernelspec:
    display_name: R
    language: R
    name: ir
---

# R lab exercises - Set 3

```{r}
# ** Libraries and packages **
    library(tidyverse)
    library(lubridate) 
    library("ggpubr")
    #install.packages('GoFKernel')
    library('GoFKernel')
    #install.packages('dplyr')
    library(dplyr)
    library(scales)
```

## Exercise 1

The triangular distribution, in the interval (a; b), is given by the following:

\begin{equation}
f(x)=
\begin{cases}
\frac{2(x-a)}{(b-a)(c-a)} & a \leq x < c \\
\frac{2(b-x)}{(b-a)(b-c)} & c \leq x \leq b \\
0 & \text{otherwise}
\end{cases}
\end{equation}

where $c \in [a,b]$

1. Plot the function, given the interval $(a; b)$
2. and write an algorithm to generate random numbers from the triangular distribution
3. Generate $10^4$ random number from the distribution, show them in an histogram and superimpose the analytical curve


### Solution

**1.** Let's create a function `dplot(a,b,c)` to plot $f(x)$ given the interval $a$ and $b$ and the coordinate $c$ of the "vertex" of the triangle:

```{r}
dplot <- function(a, b, c){    
            dfu <- function(x){                               # Define the pdf
                ifelse((x>a & x<c),
                          (2*(x-a))/((b-a)*(c-a)),
                          ifelse((x>=c & x<b),
                                (2*(b-x))/((b-a)*(b-c)),
                                0)
                          )
                }    
            x <- seq(a,b, (b-a)/1000) # Define a set of points in the interval of interest
            pdf <- dfu(x) 
            df_plot  <- data.frame(x) #Put data in dataframe to use with ggplot
            options(repr.plot.width=7, repr.plot.height=4)
            ggplot(df_plot, aes(x=x, y=pdf)) +
                    geom_line(size = 1.2, color = "hotpink1") +
                    labs(title = "Probability distribution function", 
                         subtitle = paste("for the triangular distribution in the interval [", a,",",b,
                                          "] with vertex in ",c)) +
                    theme_bw()+
                    scale_x_continuous(name= "x") +
                    scale_y_continuous(name = "pdf")
        }

# Set the parameters
a <- 0
b <- 2
c <- 0.5

dplot(a,b,c)
```

**2.** To generate random numbers we can use the inverse transform method:

```{r}
rtria <- function(N, a, b, c){
    
            x <- seq(a,b, (b-a)/1000)

            # Define the pdf
            dfu <- function(x){ifelse((x>a & x<c),                   
                                  (2*(x-a))/((b-a)*(c-a)),
                                  ifelse((x>=c & x<b),
                                        (2*(b-x))/((b-a)*(b-c)),
                                        0)
                                  )
                               } 
    
            # Integrate pdf to get cdf
            pfu <- function(x){ifelse((x>a & x<b),
                                   integrate(dfu,a,x)$value,
                                   ifelse(x <= a, 0, 1)
                                      )
                                } 
                                                                                      
            u <- runif(N) # Sample from uniform distribution
            
            # Invert cdf to sample random numbers
            rfu <- Vectorize(inverse(pfu, a, b))                   
            return(rfu(u))
    
} 

rtria(100, a,b,c)
```

**3.** Now we can sample $10^4$ random numbers from the distribution, show them in a histogram and superimpose the previously defined analytical curve.

```{r}
options(repr.plot.width=7, repr.plot.height=4)

df_rand <- data.frame(x = rtria(10000,a,b,c))

dplot(a,b,c) +
        geom_histogram(data=df_rand, aes(x=x, y=..density..), color="gold3", fill="gold1", alpha=0.3, size =0.7)+
        labs(title = paste("Triangular probability density function in the interval [",a,",",b,"] with vertex in", c),
            subtitle = expression(paste("Random sampling of ", 10^4, " values vs theoretical pdf")))
```

## Exercise 2 - Markov's inequality

Markov's inequality represents an upper bound to probability distributions:

\begin{equation}
 P(X \geq k) \leq \frac{E[X]}{k} \text{  for } k > 0
\end{equation}

Having defined a function

\begin{equation}
G(k) = 1 - F(k) \equiv P(X \geq k)
\end{equation}

plot $G(k)$ and the Markov's upper bound for:

1. the exponential, $Exp(\lambda = 1)$, distribution function
2. the uniform, $\mathscr{U}(3; 5)$, distribution function
3. the binomial, $Bin(n = 1; p = 1/2)$, distribution function
4. a Poisson, $Pois(\lambda = 1/2)$, distribution function


### Solution

Let's start by computing the function $G(k)$ and Markov's upper bound $E[X]/k$ for the 4 distributions taken into consideration. To do that, we recall that the expected values for these distributions are:

1. $E[X] = 1/ \lambda = 1 $ for the **exponential**
2. $E[X] = (a+b)/2 = 4$ for the **uniform**
3. $E[X] = np = 1/2$ for the **binomial**
4. $E[X] = \lambda = 1/2$ for the **Poisson**

```{r}
# Functions G(k)
G.exp  <- function(k) {1- pexp(k, 1)}         # exponential distribution
G.unif <- function(k) {1- punif(k, 3, 5)}     # uniform distribution
G.bin  <- function(k) {1- pbinom(k, 1, 0.5)}  # binomial distribution
G.pois <- function(k) {1- ppois(k, 0.5)}      # Poisson distribution

# Markov's upper limits (E[X] computed above)

M_up_lim <- function(k, E) E/k

E.exp  <- 1    # exponential distribution
E.unif <- 4    # uniform distribution
E.bin  <- 1/2  # binomial distribution
E.pois <- 1/2  # Poisson distribution

```

Now we can plot the results

```{r}
options(repr.plot.width=7, repr.plot.height=7)

k <-seq(0, 10, 0.5)

# Plot of exponential
df_exp  <- data.frame(k=k, G=G.exp(k), MUL = M_up_lim(k, E.exp))
exp_plot <- ggplot(df_exp) +
            geom_line(aes(x=k, y= G, color = "G(k)"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= G), color = "steelblue4", size = 1) +
            geom_line(aes(x=k, y= MUL, color ="E[x]/k"), linetype = "twodash", size = 0.8) +
            labs(title = "Exponential distribution") +
            theme_classic()+
            ylim(0,1)+
            theme(legend.position = c(0.8, 0.85))+
            scale_x_continuous(name= "k")+
            labs(y= NULL, color = " ")

# Plot of uniform
df_unif  <- data.frame(k=k, G=G.unif(k), MUL = M_up_lim(k, E.unif))
unif_plot <- ggplot(df_unif) +
            geom_line(aes(x=k, y= G, color = "G(k)"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= G), color = "steelblue4", size = 1) +
            geom_line(aes(x=k, y= MUL, color ="E[x]/k"), linetype = "twodash", size = 0.8) +
            labs(title = "Uniform distribution") +
            theme_classic()+
            ylim(0,1)+
            theme(legend.position = c(0.8, 0.85))+
            scale_x_continuous(name= "k")+
            labs(y= NULL, color = " ")

# Plot of binomial
df_bin  <- data.frame(k=k, G=G.bin(k), MUL = M_up_lim(k, E.bin))
bin_plot <- ggplot(df_bin) +
            geom_line(aes(x=k, y= G, color = "G(k)"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= G), color = "steelblue4", size = 1) +
            geom_line(aes(x=k, y= MUL, color ="E[x]/k"), linetype = "twodash", size = 0.8) +
            labs(title = "Binomial distribution") +
            theme_classic() +
            ylim(0,1) +
            theme(legend.position = c(0.8, 0.85)) +
            scale_x_continuous(name= "k") +
            labs(y= NULL, color = " ")

# Plot of Poisson
df_pois  <- data.frame(k=k, G=G.pois(k), MUL = M_up_lim(k, E.pois))
pois_plot <- ggplot(df_exp) +
            geom_line(aes(x=k, y= G, color = "G(k)"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= G), color = "steelblue4", size = 1) +
            geom_line(aes(x=k, y= MUL, color ="E[x]/k"), linetype = "twodash", size = 0.8) +
            labs(title = "Poisson distribution") +
            theme_classic() +
            ylim(0,1) +
            theme(legend.position = c(0.8, 0.85)) +
            scale_x_continuous(name= "k") +
            labs(y= NULL, color = " ")

ggarrange(exp_plot, unif_plot, bin_plot, pois_plot, ncol = 2, nrow = 2)
```

We can see that in all 4 cases $E[X]/k$ is always greater than $G(k) = P(X \geq k)$ $\forall$ $k$ as stated by Markov's inequalty.


## Exercise 3 - Chebyshev's inequality

Chebyshev's inequality tells us that

\begin{equation}
 P(|X - \mu | \geq k \sigma) \leq \frac{1}{k^2}
\end{equation}

which can also be written as

\begin{equation}
 P(|X - \mu | \geq k \sigma) \geq 1- \frac{1}{k^2}
\end{equation}

Use R to show, with a plot, that Chebyshev's inequality is is an upper bound to the following distributions:

1. a normal distribution, $N(\mu = 3, \sigma = 5)$
2. an exponential, $Exp(\lambda = 1)$
3. a uniform distribution, $\mathscr{U}(1 - \sqrt{2}; 1 + \sqrt{2})$
4. a Poisson, Pois($\lambda$ = 1/3), distribution function


### Solution

We notice that the left hand member of Chebyshev's inequalty is equivalent to:

$$
P[|X - \mu | \geq k \sigma] = P[-k \sigma \leq (X - \mu) \leq k \sigma] = P[-k \sigma + \mu \leq X \leq k \sigma + \mu] = 
F(k \sigma + \mu) - F(-k \sigma + \mu)
$$

thus we can compute it using the cumulative density function $F$ and remembering that:
1. The normal distribution has: $\mu = 3$ and $\sigma = 5$ by definition.
2. The exponential distribution has: $\mu = 1/ \lambda = 1$ and $\sigma = 1/ \lambda = 1$.
3. The uniform distribution has: $\mu = (a+b)/2 = 1$ and $\sigma = (b-a)/ \sqrt(12) = 2/ \sqrt(6)$.
4. The Poisson distribution has: $\mu = \lambda = 1/3$ and $\sigma = \sqrt(\lambda) = 1/ \sqrt(3)$.

```{r}
# Normal distribution
m.norm <- 3         
s.norm <- 5

P.norm <- function(k){
            pnorm(k*s.norm + m.norm, m.norm, s.norm) - pnorm(-k*s.norm + m.norm, m.norm, s.norm)
        }

# Exponential distribution
m.exp <- 1         
s.exp <- 1         

P.exp <- function(k){
            pexp(k*s.exp + m.exp, m.exp) - pexp(-k*s.exp + m.exp, m.exp) #N.B. rate = 1/lambda = mu
        }

# Uniform distribution
m.unif <- 1        
s.unif <- sqrt(2/3) 

P.unif <- function(k){
            punif(k*s.unif + m.unif,1-sqrt(2), 1+sqrt(2)) -  punif(-k*s.unif + m.unif, 1-sqrt(2), 1+sqrt(2))
        }

# Poisson distribution
l.pois <- 1/3       # N.B. mu = sigma^2 = lambda 

P.pois  <- function(k){
            ppois(k*sqrt(l.pois)+l.pois, l.pois) - ppois(- k*sqrt(l.pois)+l.pois, l.pois)
        }

# Chebyshev's limit
C_lim  <- function(k) {1- (1/k)^2}
```

```{r}
options(repr.plot.width=7, repr.plot.height=7)

k <-seq(0, 4, 0.1)

# Plot of normal
df_norm  <- data.frame(k=k, P=P.norm(k), CL = C_lim(k))
norm_plot <- ggplot(df_norm) +
            geom_line(aes(x=k, y= P, color = "a"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= P), color = "tomato2", size = 1) +
            geom_line(aes(x=k, y= CL, color ="b"), linetype = "twodash", size = 0.8) +
            labs(title = "Normal distribution") +
            theme_classic() +
            ylim(0,1) +
            theme(legend.position = c(0.8, 0.25)) +
            scale_colour_manual(labels =c(expression(paste("P[|X-",mu,"|<k",sigma,"]")), expression(1- (1/k)^2)),
                                breaks = c("a","b"),
                                values = c("tomato1","darkred"))+
            scale_x_continuous(name= "k") +
            labs(y= NULL, color = " ")

# Plot of exponential
df_exp  <- data.frame(k=k, P=P.exp(k), CL = C_lim(k))
exp_plot <- ggplot(df_exp) +
            geom_line(aes(x=k, y= P, color = "a"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= P), color = "mediumorchid3", size = 1) +
            geom_line(aes(x=k, y= CL, color ="b"), linetype = "twodash", size = 0.8) +
            labs(title = "Exponential distribution") +
            theme_classic()+
            ylim(0,1)+
            theme(legend.position = c(0.8, 0.25))+
            scale_colour_manual(labels =c(expression(paste("P[|X-",mu,"|<k",sigma,"]")), expression(1- (1/k)^2)),
                                breaks = c("a","b"),
                                values = c("mediumorchid1","darkorchid4"))+
            scale_x_continuous(name= "k")+
            labs(y= NULL, color = " ")

# Plot of uniform
df_unif  <- data.frame(k=k, P=P.unif(k), CL = C_lim(k))
unif_plot <- ggplot(df_unif) +
            geom_line(aes(x=k, y= P, color = "a"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= P), color = "cyan3", size = 1) +
            geom_line(aes(x=k, y= CL, color ="b"), linetype = "twodash", size = 0.8) +
            labs(title = "Uniform distribution") +
            theme_classic()+
            ylim(0,1)+
            theme(legend.position = c(0.8, 0.25))+
            scale_colour_manual(labels =c(expression(paste("P[|X-",mu,"|<k",sigma,"]")), expression(1- (1/k)^2)),
                                breaks = c("a","b"),
                                values = c("cyan1","darkcyan"))+
            scale_x_continuous(name= "k")+
            labs(y= NULL, color = " ")

# Histogram of Poisson
df_pois  <- data.frame(k=k, P=P.pois(k), CL = C_lim(k))
pois_plot <- ggplot(df_exp) +
            geom_line(aes(x=k, y= P, color = "a"), linetype = "longdash", size = 0.3) +
            geom_point(aes(x=k, y= P), color = "chartreuse3", size = 1) +
            geom_line(aes(x=k, y= CL, color ="b"), linetype = "twodash", size = 0.8) +
            labs(title = "Poisson distribution") +
            theme_classic() +
            ylim(0,1) +
            theme(legend.position = c(0.8, 0.25)) +
            scale_colour_manual(labels =c(expression(paste("P[|X-",mu,"|<k",sigma,"]")), expression(1- (1/k)^2)),
                                breaks = c("a","b"),
                                values = c("chartreuse1","forestgreen"))+
            scale_x_continuous(name= "k") +
            labs(y= NULL, color = " ")

ggarrange(norm_plot, exp_plot, unif_plot, pois_plot, ncol = 2, nrow = 2)
```

We can see that in all 4 cases $1- 1/k^2$ is always lower than $P[|X - \mu | \geq k \sigma]$ $\forall$ $k$ as stated by Chebyshev's inequalty.


## Exercise 4 - Community Mobility Open Data

Community Mobility Reports have been created with the aim to provide insights into what has changed in response to policies aimed at combating COVID-19. Data can be found at https://www.google.com/covid19/mobility/

Download and analyze the following data sets:
- https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv
and
- https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip

The data show how visitors to (or time spent in) categorized places change compared to **baseline days**. A baseline day represents a normal value for that day of the week. The baseline day is the median value from the 5-week period Jan 3 - Feb 6, 2020.

To make the reports useful, categories have been used to group some of the places with similar characteristics for purposes of social distancing guidance. The following categories are available:
* `retail and recreation`, i.e. places like restaurants,cafes, shopping centers, theme parks,museums, libraries, and movie theaters
- `grocery and pharmacy`, i.e. grocery markets, food warehouses, farmers markets, specialty food shops, drug stores, and pharmacies
- `parks`, i.e. national parks, public beaches, marinas, dog parks, plazas,and public gardens
- `transit stations`, i.e. all public transport hubs such as subway, bus, and train stations
- `workplaces`, i.e. places of work
- `residential`, i.e. people's residence

Select a couple of European countries of your choice and analyze the trends in the previous
variables over time:
- produce a plot of the data by averaging the observable over a period of one week (hint: convert the data field to `lubridate::week`) and one month and quantify the impact of COVID-19 restrictions on mobility sitations.


### Solution

Let's start by creating a tibble with the global data.

```{r}
global_data <- read_csv("Global_Mobility_Report.csv")
head(global_data)
```

Since the dataset is huge we will select and analyze data related only to a couple of European countries. Let's start with Italy and Germany.

```{r}
# Function to select data related to the country of interest
filter_country <- function(x){
                    filter(global_data, country_region_code == x)
                    }
```

```{r}
filt_IT <- filter_country('IT')       # Select entries only about Italy
filt_DE <- filter_country('DE')       # Select entries only about Germany

head(filt_IT)
tail(filt_IT)
```

We can see that the tibble contains the following informations:

* `country_region_code`: the iso code of the country
* `country_region`: the full name of the country
* `sub_region_X`: specifies the sub region (if applicable)
* `iso_3166_2_code`: the iso3166 code
* `place_id`
* `date`: the date of the year stored in yyyy-mm-dd format
* The percentage change from baseline for the following categories:
    - `retail and recreation`
    - `grocery and pharmacy`
    - `parks`
    - `transit stations`
    - `workplaces`
    - `residential`

Since the data is stored daily, fluctuations are very strong and heavily dependent on the day of the week consiedered. The data becomes more meaningful if averaged over a longer period of time. 

Let's write a function to group data by week or month and then average over it

```{r}
#Adds columns with week and month
group_data <- function(df){
                df$Month <- as.Date(cut(df$date, breaks = "month"))
                df$Week <- as.Date(cut(df$date, breaks = "week"))  
    return(df)
}

# Function to average over each week
week_avg <- function(df){
              df %>% 
              arrange(date) %>% 
              group_by(Week)%>%
              summarise_at(vars(retail_and_recreation_percent_change_from_baseline,
                                          grocery_and_pharmacy_percent_change_from_baseline,
                                          parks_percent_change_from_baseline,
                                          transit_stations_percent_change_from_baseline,
                                          workplaces_percent_change_from_baseline,
                                          residential_percent_change_from_baseline), funs(mean(., na.rm=TRUE)))
        }

# Function to average over each month
month_avg <- function(df){
              df %>% 
              arrange(date) %>% 
              group_by(Month)%>%
              summarise_at(vars(retail_and_recreation_percent_change_from_baseline,
                                          grocery_and_pharmacy_percent_change_from_baseline,
                                          parks_percent_change_from_baseline,
                                          transit_stations_percent_change_from_baseline,
                                          workplaces_percent_change_from_baseline,
                                          residential_percent_change_from_baseline), funs(mean(., na.rm=TRUE)))
        }

```

```{r}
# Italy df
week_IT <- filt_IT %>% group_data() %>% week_avg
month_IT <- filt_IT %>% group_data() %>% month_avg

# Germany df
week_DE <- filt_DE %>% group_data() %>% week_avg
month_DE <- filt_DE %>% group_data() %>% month_avg


head(week_IT)
tail(month_DE)
```

Now we can plot the weekly percent change of the different categories and compare them between the two countries:

```{r}
options(repr.plot.width=7, repr.plot.height=7)

# Plot for Italy

IT_plot <-  week_IT %>% 
              gather(key, value, -Week) %>% 
              ggplot(aes(Week, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Italy mobility reports averaged by week",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "10 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "2 weeks"))+
              ylim(-100,250)+
              theme_light()


# Plot for Germany
DE_plot <-  week_DE %>% 
              gather(key, value, -Week) %>% 
              ggplot(aes(Week, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Germany mobility reports averaged by week",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                 values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "10 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "2 weeks"))+
              ylim(-100,200)+                           
              theme_light()

ggarrange(IT_plot, DE_plot, ncol = 1, nrow = 2)
```

And by month

```{r}
options(repr.plot.width=7, repr.plot.height=7)

# Plot for Italy

IT_plot <-  month_IT %>% 
              gather(key, value, -Month) %>% 
              ggplot(aes(Month, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Italy mobility reports averaged by month",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "12 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "4 weeks"))+
              ylim(-100,200)+                           
              theme_light()

# Plot for Germany
DE_plot <-  month_DE %>% 
              gather(key, value, -Month) %>% 
              ggplot(aes(Month, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Germany mobility reports averaged by month",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "12 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "4 weeks"))+
              ylim(-100,200)+                           
              theme_light()

ggarrange(IT_plot, DE_plot, ncol = 1, nrow = 2)
```

The data trend clearly shows a steep decrease in all categories for both countries in the time period of the first lockdown (March 2020 - May 2020). The only exception is the "Residential" category as people spent more time at home.

In summer 2020, when restictions were reduced, all categories returned close to their baseline value. It is also clear that mobility around national parks, public beaches, marinas, dog parks, plazas and public gardens strongly increased due to the beginning of summer break and the fact that outdoor activities were preferred since they're less favourable for covid diffusion.

Values decreased again after summer, due to the re-introduction of restrictions, although less strongly compared to the data of the first lockdown.


We can also consider the single Region mobility reports. To select a specific file from the folder containing all the data we can use the following function:

```{r}
read_data <- function(year, country) {
    filename <- paste0( year, "_", country, "_Region_Mobility_Report.csv")
    data_direct <- "./Region_Mobility_Report_CSVs"
    filepath <- file.path(data_direct, filename)
    message(paste("Reading from file :", filepath))
    read_csv(filepath)
    }
```

Now let's consider two other european countries: Spain and France

```{r}
years <- 2020:2021

filt_FR <- map_df(years ,read_data, "FR")
filt_ES <- map_df(years ,read_data, "ES")

head(filt_FR)
head(filt_ES)
```

Now we can repeant the same analysis also for these countries.

```{r}
# France df
week_FR <- filt_FR %>% group_data() %>% week_avg
month_FR <- filt_FR %>% group_data() %>% month_avg

# Spain df
week_ES <- filt_ES %>% group_data() %>% week_avg
month_ES <- filt_ES %>% group_data() %>% month_avg


head(week_FR)
tail(month_ES)
```

```{r}
options(repr.plot.width=7, repr.plot.height=7)

# Plot for France

FR_plot <-  week_FR %>% 
              gather(key, value, -Week) %>% 
              ggplot(aes(Week, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "France mobility reports averaged by week",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "10 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "2 weeks"))+
              ylim(-100,200)+                           
              theme_light()


# Plot for Spain
ES_plot <-  week_ES %>% 
              gather(key, value, -Week) %>% 
              ggplot(aes(Week, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Spain mobility reports averaged by week",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "10 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "2 weeks"))+
              ylim(-100,100)+                           
              theme_light()

ggarrange(FR_plot, ES_plot, ncol = 1, nrow = 2)
```

```{r}
options(repr.plot.width=7, repr.plot.height=7)

# Plot for France

FR_plot <-  month_FR %>% 
              gather(key, value, -Month) %>% 
              ggplot(aes(Month, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "France mobility reports averaged by month",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "12 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "4 weeks"))+
              ylim(-100,200)+                           
              theme_light()


# Plot for Spain
ES_plot <-  month_ES %>% 
              gather(key, value, -Month) %>% 
              ggplot(aes(Month, value)) +  
              geom_line(aes(color = key), size = 0.55) +
              geom_hline(yintercept=0, linetype="dashed", color = "black")+
              labs(title = "Spain mobility reports averaged by month",
                   x = "Date", y = "Percent change from baseline", color = "Categories \n") +
              scale_colour_manual(labels = c("Grocery and pharmacy", "Parks", "Residential", "Retail and recreation",
                                           "Transit stations", "Workplaces"),
                                  values = c("coral1", "seagreen3", "gold3" , "hotpink1" , "dodgerblue1" ,"lightblue2"))+
              scale_x_date(breaks = function(x) seq.Date(from = min(x), to = max(x), by = "12 weeks"), 
                         labels = date_format("%b-%Y"), 
                         minor_breaks = function(x) seq.Date(from = min(x), to = max(x), by = "4 weeks"))+
              ylim(-100,100)+                           
              theme_light()

ggarrange(FR_plot, ES_plot, ncol = 1, nrow = 2)
```

Again, the trends are very similar to those previously observed for Italy and Germany.

```{r}

```
