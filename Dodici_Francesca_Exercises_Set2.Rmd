---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.10.3
  kernelspec:
    display_name: R
    language: R
    name: ir
---

# R lab exercises - Set 2

```{r}
# ** Libraries and packages **
    library(tidyverse)
    library(lubridate) 
    library("ggpubr")
    #install.packages('GoFKernel')
    library('GoFKernel')
```

<!-- #region -->
## Exercise 1

A set of measurements have been performed on the concentration of a contaminant in tap water. 
The following tables reports a set of values (x), with the corresponding probabilities given by the two methods ($p_1$ and $p_2$).


| $x$ | 15.58 | 15.9 |  16  | 16.1 | 16.2 |
|:-----:|:-----:|:----:|:----:|:----:|:----:|
| $p_1$ | 0.15  | 0.21 | 0.35 | 0.15 | 0.14 |
| $p_2$ | 0.14  | 0.05 | 0.64 | 0.08 | 0.09 |

Evaluate the expected values, $E[X]$, and the variance, $Var(X)$, for both methods
<!-- #endregion -->

### Solution

Using the definition of the *expected value*:

\begin{equation}
E[X] = \sum_{i} x_i p(x_i)
\end{equation}

and of the *variance*:

\begin{equation}
Var(X) = E[X − E[X]]^2 = E[X^2] − (E[X])^2
\end{equation}

It is immediate to find the result.

```{r}
# Define vectors
x <- c(15.58, 15.9, 16, 16.1, 16.2)
p1 <- c(0.15, 0.21, 0.35, 0.15, 0.14)
p2 <- c(0.14, 0.05, 0.64, 0.08, 0.09)

# Function to calculate expected value
E_x <- function(x, p) sum(x*p) 

# Function to calculate variance
var_x <- function(x, p) sum(p*x^2)-(sum(x*p))^2

print(paste("E_1[x] = ", E_x(x, p1)))
print(paste("Var_1[x] = ", var_x(x, p1)))
print(paste("E_2[x] = ", E_x(x, p2)))
print(paste("Var_2[x] = ", var_x(x, p2)))
```

## Exercise 2

The waiting time, in minutes, at the doctor's is about 30 minutes, and the distribution follows an exponential pdf with rate 1/30.
1. Simulate the waiting time for 50 people at the doctor's office and plot the relative histogram.
2. What is the probability that a person will wait for less than 10 minutes?
3. Evaluate the average waiting time from the simulated data and compare it with the expected value (calculated from theory and by manipulating the probability distributions using R)
4. What is the probability for waiting more than one hour before being received ?


### Solution

**1.** To simulate the waiting time we can extract 50 random variables from the exponential distribution with rate $\lambda = 1/30$ using `rexp()`. 
Then we can plot the histogram of these simulated waiting times. 

```{r}
lambda = 1/30 # rate of the distribution
N = 50        # number of people

wait_times <- rexp(N, lambda)  # Extract 50 random variables from the distribution
```

```{r}
# Plot with ggplot2

df_sim <- data.frame(wt=wait_times) #Convert to dataframes to use ggplot2

options(repr.plot.width=6, repr.plot.height=4)

ggplot() +
    geom_histogram(data =df_sim, aes(x=wt), color="dodgerblue4", fill="lightblue", size =0.7)+
    scale_y_continuous(name = "Counts", breaks=seq(0, 10, 2)) +
    labs(title = "Waiting time at doctor's office", 
         subtitle='Simulated waiting time for 50 people') +
    theme_minimal()+
    scale_x_continuous(name= "Waiting time [min]", breaks=seq(0,150,25)) 
```

By normalizing this histogram we can also compare it with the theoretical distribution given by `dexp()`.

```{r}
# Plot of pdf

th_dist <- dexp(0:150, lambda) # Theoretical distribution between 0 and 150
df_th  <- data.frame(x = 0:150, y = th_dist)

options(repr.plot.width=6, repr.plot.height=4)

ggplot() +
    geom_histogram(data =df_sim, aes(x=wt, y=..density..), color="dodgerblue4", fill="lightblue", size =0.7)+
    geom_line(data =df_th, aes(x, y), color="midnightblue", linetype ="dashed", size =1) +
    scale_y_continuous(name = "Probability distribution", breaks=seq(0, 0.05, 0.01)) +
    labs(title = "Waiting time at doctor's office", 
         subtitle = 'Simulated and theoretical probability distribution of waiting times') +
    theme_minimal()+
    scale_x_continuous(name= "Waiting time [min]", breaks=seq(0,150,25)) 


```

**2.** The probability that a person will wait for less than 10 minutes can be calculated determining the integral of the **pdf** for $P(t<10)$, or directly by calculating the **cdf** $F(t=10)$ with `pexp()`. We find that this probability is about the 
$28.3\%$.

```{r}
prob_10 <- pexp(10, lambda)

print(paste("The probability of waiting less than 10 minutes is: ", prob_10))
```

**3.** The average waiting time can be calculated from the simulated data by performing the average of the simulated data with `mean()`.

We can then compare these results with the expected value which is known to be $E[X] = 1/ \lambda = 30$.
The expected value can also be calculated using its definition $E[X] = \sum_{i} x_i p(x_i)$ with the exponential pdf as $p(x)$ using the R probability distribution `dexp()`.

The three results are not exactly identical but by increasing the number of simulated times and the number of $x_i$ in the calculation of $E[X]$ by definition all values will converge to theoretical value of **30**. 

```{r}
mean_wt <- mean(wait_times) # Average

xi <- 1:150
E_calc_wt <- E_x(xi, dexp(xi, lambda)) # Use function defined in Ex 1 to compute E[X]

th_wt <- 1/lambda # Theoretical result

print(paste("Average waiting time by performing mean of simulated data:", mean_wt))
print(paste("The expected waiting time calculated using the definition of E[X]:", E_calc_wt))
print(paste("The theoretical waiting time is:", th_wt))
```

**4.** The probability of waiting more than one hour before being received can be computed determining the integral of the pdf for $P(t>60)$ , or directly by calculating the complementary of the cdf for $t=60$ $\Longrightarrow P(t>60) = 1- F(t=60)$. 

We find that this probability is about the $13.5\%$

```{r}
prob_60 <- pexp(60, lambda)

print(paste("The probability of waiting more than 1 hour is: ", 1- prob_60))
```

## Exercise 3

Let's suppose that on a book, on average, there is one typo error every three pages.

If the number of errors follows a Poisson distribution, plot the pdf and cdf, and calculate the probability that there is at least one error on a specific page of the book.


### Solution

Saying that on average there is one typo error every three pages in a book where the number of errors follows a Poisson distribution means that $\lambda = 1/3$. We can plot the pdf and cdf of this distribution by using `dpois()` and `ppois()` respectively.

```{r}
lambda <- 1/3

typ <- 0:6
pdf <- dpois(typ, lambda)
cdf <- ppois(typ, lambda)

# Plot of pdf and cdf

df_pois  <- data.frame(typ, pdf, cdf)

options(repr.plot.width=7, repr.plot.height=3)

p_plot <- ggplot(df_pois, aes(x=typ, y=pdf)) +
            geom_line(color="maroon2", linetype ='dotted', size = 0.8) +
            geom_point(color="maroon4", shape=15, size = 1.2)+
            labs(title = "Probability density function") +
            theme_classic()+
            scale_x_continuous(name= "Number of typos in page", breaks=seq(0,8,2))+
            scale_y_continuous(name = NULL , breaks=seq(0, 0.8, 0.2))

c_plot <- ggplot(df_pois, aes(x=typ, y=cdf)) +
            geom_line(color="springgreen3", linetype ='dotted', size = 0.8) +
            geom_point(color="springgreen4", shape=15, size = 1.2)+            
            labs(title = "Cumulative density function") +
            theme_classic()+
            scale_x_continuous(name= "Number of typos in page", breaks=seq(0,8,2))+
            scale_y_continuous(name = NULL , breaks=seq(0, 1, 0.1))

ggarrange(p_plot, c_plot, ncol = 2, nrow = 1)
```

The probability to have at least one error on a specific page of the book can be calculated as the complementary of the probability of having no errors: $1-F(X=0)$ where F is the cumulative probability. 

We find that this probability is the $28.3 \%$.

```{r}
p_noerr = 1-ppois(0, lambda) 
print(paste("Probability of having at least one error on a specific page:", p_noerr))
```

## Exercise 4

We randomly draw cards from a deck of 52 cards, with replacement, until one ace is drawn. 

Calculate the probability that at least 10 draws are needed.


### Solution

Since there are 4 aces in the deck, the probability to draw one is $p = 4/52$. The distribution that models this problem is the geometric distribution with probability of success $p$.

The probability of needing at least 10 draws to get the first ace can be computed as $1$ minus the probability of extracting it in 9 draws. This is equal to $1-$ the cdf $F(9)$ of the geometric distribution `pgeom()`. 

\begin{equation}
 P(x\geq10) = 1- P(x\leq9)= 1 - \sum^9_{i=1} p(1-p)^{i-1} = 1-F(X=9)
\end{equation}

We find that this probability is the $44.9 \%$

```{r}
p10 = 1-pgeom(9, 4/52)
print(paste("The probability that at least 10 draws are needed is:", p10))
```

## Exercise 5

The time it takes a student to complete a TOLC-I University orientation and evaluation test follows a density function of the form:

\begin{equation}
f(t)=
\begin{cases}
c(t-1)(2-t) & 1<t<2\\
0 & \text{otherwise}
\end{cases}
\end{equation}

where t is the time in hours.

1. Using the `integrate()` R function, determine the constant c (and verify it analytcally)
2. Write the set of four R functions and plot the pdf and cdf, respectively.
3. Evaluate the probability that the student will finish the aptitude test in more than 75 minutes. *And that it will take between 90 and 120 minutes* *.

**  **Note**: the text of the exercise said "And that it will take 90 and 120 minutes." but I supposed a "between" was missing since the probability of taking **exactly** a certain amount of time with a continuous distribution like the one of the exercise is equal to zero $p(t=90) = 0$ and $p(t=120) =0$. You need a finite interval to calculate a finite probability.


### Solution

**1.** Since $f(t)$ is a probability density function, we know it must be normalized to have integral equal to 1 in its domain. Thus, we can determine the value of $c$ such that this constraint is actually verified:

\begin{equation}
\int_1^2 f(t) dt = 1 \Longrightarrow c \int_1^2 (t-1)(2-t) dt = 1 \Longrightarrow c = \left[ \int_1^2 (t-1)(2-t) dt \right]^{-1}
\end{equation}

We can easily compute the analytical result of this integral:

\begin{equation}
\begin{split}
&\int_1^2 (t-1)(2-t) dt = \int_1^2 2t - t^2 -2 +t dt = \int_1^2 -t^2+3t-2 dt = \left[ \frac{3t^2}{2}-\frac{t^3}{3} -2t \right]_1^2 = 6 - \frac{8}{3} - 4 - \frac{3}{2} + \frac{1}{3} + 2 = \frac{1}{6}\\
& \Longrightarrow c = \left[ \frac{1}{6} \right]^{-1} = 6
\end{split}
\end{equation}

This result can be also computed numerically using the function `integrate()` as below

```{r}
# Integrate using function as anonymous function:

f_integral <- integrate(function(x) {(x-1)*(2-x)}, lower = 1, upper = 2)
c <- 1/f_integral$value

print(paste("c = ", c))
```

**2.** The first R function we can define is the **probability density function** `dfunc` which is simply given by $f(t)$ with $c=6$

```{r}
dfunc <- function (t) {
    dfu <- ifelse((t>1 & t<2), c*(t-1)*(2-t), 0)
    return (dfu)
}

dfunc <- Vectorize(dfunc)
```

Then we can define the **cumulative distribution function** `pfunc` defined as $F(X) = \int_{-\infty}^X f(t) dt$

\begin{equation}
F(X)= 
\begin{cases}
0 & X\leq 1\\
\int_1^X 6\cdot(t-1)(2-t) dt & 1<X<2\\
1 & X \geq 2 \\
\end{cases}
\end{equation}

We already computed the integral of the $pdf$:
$$
 6 \cdot \left[ \frac{3t^2}{2}-\frac{t^3}{3} -2t \right]_{1}^X = \left[ 9t^2-2t^3 -12t \right]_{1}^X = 9X^2-2X^3 -12X +5
$$

We can thus compute it using both the analytical and the numeric value of the $pdf$'s integral:

```{r}
# With analytical integration

pfunc_an <- function (X) {
    pfu <- ifelse((X>1 & X<2), 
                  9*X^2-2*X^3 -12*X +5,
                  ifelse(X <= 1, 0, 1)
                 )
    return (pfu)
}
pfunc_an <- Vectorize(pfunc_an)

# Using integrate()

pfunc_nu <- function(X) {
    pfu <- ifelse((X>1 & X<2), 
                  integrate(dfunc,1,X)$value,
                  ifelse(X <= 1, 0, 1)
                 )
    return (pfu)
}

pfunc_nu <- Vectorize(pfunc_nu)
```

Then there is the **quantile function** `qfunc` which is the inverse of the cumulative distribution: $q(X) = F^{-1}(X)$. To invert this expression we can use the function `inverse()` of the `GoFKernel` package, specifically designed to calculate the inverse function of a cumulative distribution function.

```{r}
qfunc <- inverse(pfunc_an, 1, 2)  

qfunc <- Vectorize(qfunc)
```

Finally, we can use the inverse trasform method to define the function `rfunc` which allows to **generate random numbers sampled from our distribution**.

```{r}
rfunc <- function(N, cdf, inf, sup) {
    u <- runif(N)
    rfu <- Vectorize(inverse(cdf, inf, sup)) #invert the cdf in the interval specified
    return (rfu(u))
}
```

To check our results we can plot the $pdf$, the $cdf$, the quantile and a hisogram of the sampled random numbers:

```{r}
t <- seq(0.5, 2.5, 0.05)
pdf <- dfunc(t)
cdf1 <- pfunc_an(t)
cdf2 <- pfunc_nu(t)
qua <- qfunc(cdf1)
ran <- rfunc(2000, pfunc_an, 0.5, 2.5) # Sample 1000 random numbers in the interval [0.5,2.5]) 

df_plots  <- data.frame(t, pdf, cdf1, cdf2, qua)
df_rand <- data.frame(time = ran)

options(repr.plot.width=7, repr.plot.height=7)

# Plot of pdf
d_plot <- ggplot(df_plots, aes(x=t, y=pdf)) +
            geom_line(color="deepskyblue1", size = 0.3) +
            geom_point(color="deepskyblue4", size = 1.2)+
            labs(title = "Probability density function") +
            theme_classic()+
            scale_x_continuous(name= "time [hours]")+
            scale_y_continuous(name = NULL , breaks=seq(0, 1.5, 0.3))

# Plot of the two cdfs
p_plot <- ggplot(df_plots) +
            geom_line(aes(x=t, y=cdf1, color="Analytical"), linetype ='longdash', size = 0.2) +
            geom_point(aes(x=t, y=cdf2, color="Numerical"), shape=4, size = 1.5)+
            labs(title = "Cumulative density function") +
            theme_classic()+
            theme(legend.position = c(0.8, 0.2))+
            scale_x_continuous(name= "time [hours]")+
            scale_y_continuous(name = NULL , breaks=seq(0, 1, 0.2))+
            labs(color = " ")

# Plot of quantile
q_plot <- ggplot(df_plots, aes(x=cdf1, y=qua)) +
            geom_line(color="mediumpurple1", size = 0.3) +
            geom_point(color="mediumpurple4", size = 1.2)+
            labs(title = "Quantile") +
            theme_classic()+
            scale_x_continuous(name= "cdf")+
            scale_y_continuous(name = "time [hours]" , breaks=seq(1, 2, 0.2))

# Histogram of random numbers
r_hist <- ggplot() +
            geom_histogram(data =df_rand, aes(x=time, y=..density..), color="gold3", fill="gold1", alpha=0.3, size =0.7)+
            geom_line(data =df_plots, aes(x=t, y=pdf, color = "pdf"), linetype ="dotted", size = 0.9) +
            labs(title = "Random sampling of 2000 numbers") +
            theme_classic()+
            theme(legend.position = c(0.8, 0.85))+
            scale_x_continuous(name= "time [hours]", breaks = seq(0.5, 2.5, 0.5))+
            scale_y_continuous(name = NULL , breaks=seq(0, 1.5, 0.3))+
            scale_colour_manual(" ", breaks = "pdf", values = "deepskyblue4")

ggarrange(d_plot, p_plot, q_plot, r_hist, ncol = 2, nrow = 2)
```

**3.** Now, to evaluate the probability that the student will finish the aptitude test in more than 75 minutes (1.25 hr) we can use the $cdf$ and calculate $1- F(1.25)$. This is equivalent to integrating the $pdf$ in the interval of interest. Both methods lead to the same result: the probability is about $84.4 \%$.

Similarly, to calculate the probability that a student will take between 90 and 120 minutes (1.5-2 hr), we can either integrate the $pdf$ between 1.5 and 2 or using directly the $cdf$: $F(2)-F(1.5)$. In both cases the result is a $50 \%$ probability.

```{r}
# Prob of needing more than 75 min
pd_75 <- integrate(dfunc, 75/60, Inf) # Integrating the pdf
pp_75 <- 1- pfunc_an(75/60)           # Using the cdf

print("The probability that a student will finish the aptitude test in more than 75 minutes is:")
print(paste("using the pdf:", pd_75$value))
print(paste("using the cdf:", pp_75))

# Prob of needing between 90 and 120 min
pd_90_120 <- integrate(dfunc, 90/60, 120/60)     # Integrating the pdf
pp_90_120 <- pfunc_an(120/60) - pfunc_an(90/60) # Using the cdf


print("The probability of taking between 90 and 120 minutes to finish the test is:")
print(paste("using the pdf:", pd_90_120$value))
print(paste("using the cdf:", pp_90_120))
```

## Exercise 6

The lifetime of tires sold by an used tires shop is $10^4 \cdot x$ $km$, where $x$ is a random variable following the distribution funcion:

\begin{equation}
f(x)=
\begin{cases}
2/x^2 & 1<x<2\\
0 & \text{otherwise}
\end{cases}
\end{equation}

1. Write the set of four R functions and plot the pdf and cdf, respectively.
2. Determine the probability that tires will last less than 15000 km
3. Sample 3000 random variables from the distribution and determine the mean value and the variance, using the expression $Var(X) = E[X^2] - E[X]^2$


### Solution
**1.** We can proceed in the same fashion as in the previous exercise to define:
* `dtires` the probability density function
* `ptires` the cumulative distribution function
* `qtires` the quantile
* `rtires` to sample random numbers from the distribution

Since the distribution function is very simple we can integrate it analytically to find the cdf $F(X) = \int_{-\infty}^X 2/x^2 dx$: 

\begin{equation}
F(X)= 
\begin{cases}
0 & X\leq 1\\
-2/X + 2 & 1<X<2\\
1 & X \geq 2 \\
\end{cases}
\end{equation}

And we can also invert it analytically to find the quantile and to sample random numbers using the inverse transform method:
$F^{-1}(u)= \frac{2}{(2-u)}$


```{r}
# Probability density function --------------------------------------------------

dtires <- function (x) {
    dfu <- ifelse((x>1 & x<2), 2/x^2, 0)
    return (dfu)
}

dtires <- Vectorize(dtires)

# Cumulative distribution function ----------------------------------------------
ptires <- function (X) {
    pfu <- ifelse((X>1 & X<2), 
                  (-2/X+2),
                  ifelse(X <= 1, 0, 1)
                 )
    return (pfu)
}
prires <- Vectorize(ptires)

# Quantile ----------------------------------------------------------------------
qtires <- function (p) {
    qfu <- 2/(2-p)
    return (qfu)
}
qrires <- Vectorize(qtires)

# Random sampling ---------------------------------------------------------------
rtires <- function (N){
    u <- runif(N)
    rfu <- Vectorize(2/(2-u))
    return(rfu)
}
```

```{r}
#Plots to check results

x <- seq(0.8, 2.2, 0.02)
pdf <- dtires(x)
cdf <- ptires(x)
qua <- qtires(cdf)
ran <- rtires(2000) # Sample 1000 random numbers in the interval [1,2]) 

df_plots  <- data.frame(x, pdf, cdf, qua)
df_rand <- data.frame(ex = ran)

options(repr.plot.width=7, repr.plot.height=7)

# Plot of pdf
d_plot <- ggplot(df_plots, aes(x=x, y=pdf)) +
            geom_line(color="deepskyblue1", linetype ="dashed", size = 0.3)+
            geom_point(color="deepskyblue4", size = 1.2)+
            labs(title = "Probability density function")+
            theme_classic()+
            scale_x_continuous(name= "x")+
            scale_y_continuous(name = NULL)

# Plot of cdf
p_plot <- ggplot(df_plots, aes(x=x, y=cdf))+
            geom_line(color="red1", linetype ="dashed", size = 0.3)+
            geom_point(color="red4", size = 1.2)+
            labs(title = "Cumulative density function")+
            theme_classic()+
            scale_x_continuous(name= "x")+
            scale_y_continuous(name = NULL)

# Plot of quantile
q_plot <- ggplot(df_plots, aes(x=cdf, y=qua)) +
            geom_line(color="mediumpurple1", linetype ="dashed", size = 0.3) +
            geom_point(color="mediumpurple4", size = 1.2)+
            labs(title = "Quantile") +
            theme_classic()+
            scale_x_continuous(name= "cdf")+
            scale_y_continuous(name = "x")

# Histogram of random numbers
r_hist <- ggplot() +
            geom_histogram(data =df_rand, aes(x=ex, y=..density..), color="gold3", fill="gold1", alpha=0.3, size =0.7) +
            geom_line(data =df_plots, aes(x=x, y=pdf, color = "pdf"), linetype ="dotted", size = 0.9) +
            labs(title = "Random sampling of 2000 numbers") +
            theme_classic()+
            theme(legend.position = c(0.8, 0.85))+
            scale_x_continuous(name= "x")+
            scale_y_continuous(name = NULL)+
            scale_colour_manual(" ", breaks = "pdf", values = "deepskyblue4")

ggarrange(d_plot, p_plot, q_plot, r_hist, ncol = 2, nrow = 2)
```

**2.** The probability that the tires will last less than $15000 km$ can be computed as the integral of the pdf with upper limit $x = 15000 \cdot 10^{-4} km = 1.5 km$ or directly with the cdf as $F(X=1.5)$. The probability is of about the $66.7 \%$.

```{r}
# Prob of lasting less than 15000km
pd_1.5 <- integrate(dtires, -Inf, 1.5) # Integrating the pdf
pp_1.5 <- ptires(1.5)                  # Using the cdf

print("The probability that the tires will last less than 15000 km is:")
print(paste("using the pdf:", pd_1.5$value))
print(paste("using the cdf:", pp_1.5))
```

**3.** We can determine the expected value either by calculating the average of the 3000 random variables sampled from the distribution or by using its definition:

$$
E(X) = \int_{-\infty}^{+\infty} x f(x) dx = \int_1^2 2/x dx 
$$

the variance can be calculated as:
$$
Var(X) = E[X^2] - E[X]^2
$$

```{r}
x <- seq(1, 2, 1/3000)

avg <- mean(rtires(3000))
Ex <- integrate(function(x) {x*dtires(x)}, 1, 2)
E.x2 <- integrate(function(x) {x^2*dtires(x)}, 1, 2)

var <-  E.x2$value - (Ex$value)^2

print(paste("Theoretical expected value:", Ex$value))
print(paste("Experimental mean:", avg))
print(paste("Variance:", var))
```

We find that the average mean is approximately $1.386$ and the variance is $0.078$.

```{r}

```

```{r}

```
